üöó Motor de Predicci√≥n de Riesgo de Siniestralidad VialProyecto: Desaf√≠o Smart Cities Duoc UC 2025Informe T√©cnico Asociado: Smart City.docx1. Resumen del ProyectoEste repositorio contiene la soluci√≥n t√©cnica para el Desaf√≠o Smart Cities Duoc UC 2025. El n√∫cleo de este proyecto es un "Motor de Riesgo" (IA Tabular), un modelo de Machine Learning dise√±ado para predecir la severidad de los siniestros de tr√°nsito en la Regi√≥n Metropolitana.Utilizando un conjunto de datos consolidado de 63,689 puntos de siniestros √∫nicos (2020-2024), se entren√≥ un clasificador XGBoost. El modelo final, que incorpora ingenier√≠a de caracter√≠sticas como clustering geoespacial (DBSCAN), es capaz de discriminar entre puntos de "Bajo Riesgo" y "Alto Riesgo" con un AUROC de 0.7191. Este motor sirve como el backend para la API de predicci√≥n (/predict).2. üìÇ Estructura del RepositorioEl proyecto est√° organizado para cumplir con los requisitos de la hackathon (/src, /api, /app) y asegurar la reproducibilidad./
‚îú‚îÄ‚îÄ /api/             # C√≥d. de la API (FastAPI) y artefactos del modelo
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ modelo_riesgo_vX.joblib
‚îÇ   ‚îî‚îÄ‚îÄ preprocesador_vX.joblib
‚îÇ
‚îú‚îÄ‚îÄ /app/             # C√≥d. de la App Demo (Streamlit)
‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îÇ
‚îú‚îÄ‚îÄ /src/             # Scripts de entrenamiento y limpieza
‚îÇ   ‚îú‚îÄ‚îÄ Limpieza.py
‚îÇ   ‚îú‚îÄ‚îÄ entrenar_modelo.py
‚îÇ   ‚îî‚îÄ‚îÄ analizar_fairness.py
‚îÇ
‚îú‚îÄ‚îÄ /data_raw/        # (Input) CSVs brutos de siniestralidad
‚îÇ
‚îú‚îÄ‚îÄ /data_processed/  # (Generado) Dataset maestro limpio
‚îÇ   ‚îî‚îÄ‚îÄ Siniestros_Maestro_Consolidado_HACKATHON_FINAL.csv
‚îÇ
‚îú‚îÄ‚îÄ /kb/              # (Input) Base de conocimiento para el Coach RAG
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt  # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md         # Este archivo
3. üõ†Ô∏è Instalaci√≥n y DependenciasPara levantar el proyecto localmente, sigue estos pasos:Clonar el repositorio:Bashgit clone [URL_DEL_REPO]
cd [NOMBRE_DEL_REPO]
Crear un entorno virtual (recomendado):Bashpython -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
Instalar dependencias:El archivo requirements.txt contiene todas las librer√≠as necesarias.Bashpip install -r requirements.txt
Librer√≠as clave: pandas, xgboost, scikit-learn, fastapi, uvicorn, joblib, numpy, streamlit.4. üöÄ Flujo de Ejecuci√≥n (Paso a Paso)Paso 1: Procesamiento de Datos (ETL)Coloca todos los archivos .csv de siniestros brutos dentro de la carpeta /data_raw/. El script Limpieza.py unifica, limpia y agrupa los datos por coordenadas.Bash# Navega a la carpeta de scripts
cd src

# Ejecuta la limpieza
# Input: /data_raw/*.csv
# Output: /data_processed/Siniestros_Maestro_Consolidado_HACKATHON_FINAL.csv
python Limpieza.py
Paso 2: Entrenamiento del ModeloEjecuta el script de entrenamiento principal. Este script realiza la ingenier√≠a de caracter√≠sticas (DBSCAN), el afinamiento de hiperpar√°metros (RandomizedSearchCV) y la validaci√≥n.Bash# Desde la carpeta /src/
python entrenar_modelo.py
Input: /data_processed/Siniestros_Maestro_Consolidado_HACKATHON_FINAL.csvOutput (en /src/): modelo_riesgo_vX.joblib y preprocesador_vX.joblibPaso 3: Mover ArtefactosMueve los dos archivos .joblib generados desde la carpeta /src/ a la carpeta /api/ para que el servidor de FastAPI pueda cargarlos.Paso 4: Ejecutar la API (FastAPI)Esta API expone los endpoints /predict y /coach.Bash# Navega a la carpeta de la API
cd ../api

# Inicia el servidor
uvicorn main:app --reload
La API estar√° disponible en http://127.0.0.1:8000.Puedes ver la documentaci√≥n interactiva en http://127.0.0.1:8000/docs.Paso 5: Ejecutar la App Demo (Streamlit)En una terminal separada, lanza la aplicaci√≥n web interactiva.Bash# Navega a la carpeta de la app
cd ../app

# Inicia Streamlit
streamlit run app.py
La aplicaci√≥n estar√° disponible en http://127.0.0.1:8501.5. üìä Detalles del Modelo y M√©tricasEl desarrollo del modelo se centr√≥ en un clasificador XGBoost.Ingenier√≠a de Caracter√≠sticas: La variable clave fue Hotspot_Cluster, generada por un algoritmo DBSCAN que identific√≥ 8 clusters de alta densidad de siniestros.Manejo de Desbalance: Se utiliz√≥ el hiperpar√°metro scale_pos_weight (valor: 3.38) para forzar al modelo a priorizar la detecci√≥n de la clase minoritaria ("Alto Riesgo").Validaci√≥n: El modelo se evalu√≥ contra un set de prueba (20% de los datos) usando una divisi√≥n estratificada. El an√°lisis de la validaci√≥n temporal (V5) fue crucial y demostr√≥ un colapso del modelo (AUROC 0.437) debido al concept drift post-pandemia. El modelo V4 (split aleatorio) se reporta aqu√≠ como el baseline de rendimiento, reconociendo esta limitaci√≥n.M√©tricas de Desempe√±o (Modelo V4)Los resultados del modelo afinado en el set de prueba son:M√©tricaPuntajeR√∫bricaAUROC (Principal)0.71917 pts (0.70‚Äì0.74)Brier Score0.21031 pt (> 0.18)AUPRC0.4352N/ARecall (Alto Riesgo)0.68N/ANota: El modelo fue optimizado para Recall (sensibilidad), priorizando la minimizaci√≥n de Falsos Negativos (peligros no detectados). El Brier Score bajo (1 pt) fue un trade-off aceptado para maximizar la detecci√≥n (Recall) mediante scale_pos_weight.
